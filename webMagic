

 
WebMagic 框架                                       

四大组件

1.Downloader

 

Downloader负责从互联网上下载页面，以便后续处理。WebMagic默认使用了Apache HttpClient作为下载工具。

 

2.PageProcessor

 

PageProcessor负责解析页面，抽取有用信息，以及发现新的链接。WebMagic使用Jsoup作为HTML解析工具，并基于其开发了解析XPath的工具Xsoup。

 

在这四个组件中，PageProcessor对于每个站点每个页面都不一样，是需要使用者定制的部分。

 

3.Scheduler

 

Scheduler负责管理待抓取的URL，以及一些去重的工作。WebMagic默认提供了JDK的内存队列来管理URL，并用集合来进行去重。也支持使用Redis进行分布式管理。

 

除非项目有一些特殊的分布式需求，否则无需自己定制Scheduler。

 

4.Pipeline

 

Pipeline负责抽取结果的处理，包括计算、持久化到文件、数据库等。WebMagic默认提供了“输出到控制台”和“保存到文件”两种结果处理方案。

 

Pipeline定义了结果保存的方式，如果你要保存到指定数据库，则需要编写对应的Pipeline。对于一类需求一般只需编写一个Pipeline。              

 

链式抽取API

如：List<String> urls = page.getHtml().css("div.pagination").links().regex(".*/search/\?l=java.*").all();
page.addTargetRequests(urls);

 
   
   方法  说明 示例
   
 
  xpath(String xpath)使用XPath选择html.xpath("//div[@class='title']")
  
 
  
  $(String selector)
  
  
  使用Css选择器选择
  
  
  html.$("div.title")
  
 
 
  
  $(String selector,String attr)
  
  
  使用Css选择器选择
  
  
  html.$("div.title","text")
  
 
 
  
  css(String selector)
  
  
  功能同$()，使用Css选择器选择
  
  
  html.css("div.title")
  
 
 
  
  links()
  
  
  选择所有链接
  
  
  html.links()
  
 
 
  
  regex(String regex)
  
  
  使用正则表达式抽取
  
  
  html.regex("\(.*?)\")
  
 
 
  
  regex(String regex,int group)
  
  
  使用正则表达式抽取，并指定捕获组
  
  
  html.regex("\(.*?)\",1)
  
 
 
  
  replace(String regex, String replacement)
  
  
  替换内容
  
  
  html.replace("\ 
 
  
.*\
  ","")
  
 


 

这部分抽取API返回的都是一个Selectable接口，意思是说，抽取是支持链式调用的。

 

好处： 非常方便，灵活

缺点： 弱化了类型，难以发现潜在的bug，比如说，选出来的selectable 不一定是符合你需要的类型。

 

 

持久化:支持多种持久化策略，例如同时保存到数据库和文件中。

 

HelpUrl/TargetUrl的爬虫开发模式：TargetUrl是我们最终要抓取的URL，最终想要的数据都来自这里；而HelpUrl则是为了发现这个最终URL，我们需要访问的页面。

 

WebMagic的一大特色就是可以灵活的定制组件功能，实现你自己想要的功能。

 

 

 

Ps:

page.addTargetRequests(page.getHtml().links().regex("(https://github\\.com/\\w+/\\w+)").all());

个人认为，url的抽取与过滤应该独立为一个方法

